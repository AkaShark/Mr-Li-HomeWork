{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# HomeWord 1 : Linear Regression\n",
    "本次实验的目标： 由前9个小时的18个特征预测第10个小时的PM2.5\n",
    "[参考](https://colab.research.google.com/drive/131sSqmrmWXfjFZ3jWSELl8cm0Ox5ah3C#scrollTo=NzvXP5Jya64j)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  tqdm import tqdm"
   ]
  },
  {
   "source": [
    "## Preprocssing 数据预处理\n",
    "取需要的数值部分，将'RAINFALL'全部设置为0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv', encoding='big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抛去数据的前三列不要了\n",
    "data = data.iloc[:, 3:]\n",
    "# 将为NR的数据变为 0\n",
    "data[data == 'NR'] = 0\n",
    "raw_data = data.to_numpy()"
   ]
  },
  {
   "source": [
    "## Extract Features 特征提取 - 1 \n",
    "将原始的4320*18的资料依照每个月组成12个月 18*480的数据类型(12*18*480) 其中18是feature 480 是 20*24 得来的"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = {}\n",
    "for month in range(12):\n",
    "    sample = np.empty([18, 480]) # 创建一个空样本大小为18*480\n",
    "    for day in range(20): # 一个月只取了20天\n",
    "        # 从raw_data中取数据 将数据填充进 sample\n",
    "        sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
    "    month_data[month] = sample"
   ]
  },
  {
   "source": [
    "## Extract Features 特征提取 - 2\n",
    "每个月有480小时，每9个小时为一个data，每个月会有471个data，故总资料数为471\\*12笔，而每笔数据有9\\*18的feature(一个小时18个feature)\n",
    "\n",
    "对应的target则有471 * 12 个 （第10个小时的PM2.5）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出的大小\n",
    "x = np.empty([12 * 471, 18 * 9], dtype=float)\n",
    "y = np.empty([12 * 471, 1], dtype = float)\n",
    "\n",
    "for month in range(12):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):\n",
    "            # 防止今天的数据跑到明天去\n",
    "            if day == 19 and hour > 14:\n",
    "                continue\n",
    "            # 输入的sample大小为9*18\n",
    "            x[month * 471 + day * 24 + hour, :] = month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1,-1)\n",
    "            y[month * 471 + day + hour, 0] = month_data[month][9, day * 24 + hour + 9]\n"
   ]
  },
  {
   "source": [
    "## Normalize 归一化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_x = np.mean(x, axis=0)\n",
    "std_x = np.std(x, axis= 0)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
   ]
  },
  {
   "source": [
    "上面的数据处理部分已懵逼！ 需要再看看咋做的 并想为啥这样操作\n",
    "\n",
    "## Split Training Data Into \"train_set\" and \"validation_set\"\n",
    "生成训练用的数据集train_set和验证数据局validation_set\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# floor() 返回数字的下舍整数。 取百分之80做训练集 剩下的 百分之20做测试集\n",
    "x_train_set = x[: math.floor(len(x) * 0.8), :]\n",
    "y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
    "x_validation = x[math.floor(len(x) * 0.8):, :]\n",
    "y_validation = y[math.floor(len(x) * 0.8):, :]"
   ]
  },
  {
   "source": [
    "## Training\n",
    "使用Adagrad算法作为优化器\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Testing\n",
    "导入test data 并且以训练集的方式预处理，使得测试数据形成240个维度为18\\*9+1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 因为常数项的存在所以dim要多加一个维度\n",
    "dim = 18 * 9 + 1\n",
    "w = np.zeros([dim, 1])\n",
    "x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "\n",
    "# 设置学习率\n",
    "learning_rate = 200 \n",
    "# 迭代次数\n",
    "iter_time = 1000000\n",
    "# adagrad \n",
    "adagrad = np.zeros([dim, 1])\n",
    "eps = 0.000000001\n",
    "last_loss = 0\n",
    "for t in tqdm(range(iter_time)):\n",
    "    # rmse\n",
    "    # loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2))/471/12)         \n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(x,w)-y,2))/len(x))\n",
    "    last_loss = loss\n",
    "    # # 计算梯度 这里的梯度怎么算的?? \n",
    "    # gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y)\n",
    "    # # adgrade 一路走来的梯度平方和  \n",
    "    # adagrad += gradient ** 2\n",
    "    # # 更新参数 adgeade \n",
    "    # w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    gradient = (np.dot(x.T,np.dot(x,w)-y))/(loss)\n",
    "    adagrad += (gradient ** 2)\n",
    "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    if t == 1:\n",
    "        print(\"Loss:\" + str(loss))\n",
    "\n",
    "print(\"\\n\" + \"Loss:\" + str(last_loss))\n",
    "# 保存权重\n",
    "np.save('weight.npy', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为存在偏差bias，所以dim+1\n",
    "dim = 18 * 9 + 1\n",
    "# w维度为163*1\n",
    "w = np.zeros([dim,1])\n",
    "# x_train_set维度为 4521*163\n",
    "x_train_set= np.concatenate((np.ones([len(x_train_set),1]),x_train_set),axis = 1).astype(float)\n",
    "#设置学习率\n",
    "learning_rate = 10\n",
    "#设置迭代数\n",
    "iter_time = 30000\n",
    "#让dw值初始化\n",
    "adagrad = np.zeros([dim,1])\n",
    "eps = 0.0000000001\n",
    "for t in range(iter_time):\n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(x_train_set,w)-y_train_set,2))/len(x_train_set))\n",
    "    if(t%100 == 0):\n",
    "        print(\"迭代的次数：%i ， 损失值：%f\"%(t,loss))\n",
    "        gradient = (np.dot(x_train_set.T,np.dot(x_train_set,w)-y_train_set))/(loss*len(x_train_set))\n",
    "        adagrad += (gradient ** 2)\n",
    "        w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "#保存参数w\n",
    "np.save('weight.npy',w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = np.sqrt(np.sum(np.power(np.dot(x,w)-y,2))/len(x_train_set))\n",
    "\n",
    "# gradient = (np.dot(x.T,np.dot(x,w)-y))/(loss*len(x))\n",
    "# gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('./test.csv', header = None, encoding = 'big5')\n",
    "test_data = testdata.iloc[:, 2:]\n",
    "test_data[test_data == 'NR'] = 0\n",
    "test_data = test_data.to_numpy()\n",
    "test_x = np.empty([240, 18*9], dtype = float)\n",
    "for i in range(240):\n",
    "    test_x[i, :] = test_data[18 * i: 18* (i + 1), :].reshape(1, -1)\n",
    "\n",
    "# 归一化\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1).astype(float)"
   ]
  },
  {
   "source": [
    "## Prediction \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入权重\n",
    "w = np.load('weight.npy')\n",
    "# 解决输出\n",
    "ans_y = np.dot(test_x, w)"
   ]
  },
  {
   "source": [
    "## Save Prediction to CSV File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('prediction.csv', mode='w', newline='') as prediction_file:\n",
    "    csv_writer = csv.writer(prediction_file)\n",
    "    header = ['id', 'value']\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(240):\n",
    "        row = ['id_' + str(i), ans_y[i][0]]\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "source": [
    "## 总结\n",
    "结果好像不是很好哎，因为预测的pm2.5的值竟然有负数！！ 这是不可能的啊\n",
    "如何优化呢， 选择不同的优化器，是不用同的model（LSTM）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(ans_y)):\n",
    "    if (ans_y[i] < 0):\n",
    "        count += 1\n",
    "\n",
    "count/len(ans_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}