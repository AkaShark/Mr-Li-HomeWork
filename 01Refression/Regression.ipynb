{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# HomeWord 1 : Linear Regression\n",
    "本次实验的目标： 由前9个小时的18个特征预测第10个小时的PM2.5\n",
    "[参考](https://colab.research.google.com/drive/131sSqmrmWXfjFZ3jWSELl8cm0Ox5ah3C#scrollTo=NzvXP5Jya64j)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  tqdm import tqdm"
   ]
  },
  {
   "source": [
    "## Preprocssing 数据预处理\n",
    "取需要的数值部分，将'RAINFALL'全部设置为0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv', encoding='big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         日期  測站        測項     0     1     2     3     4     5     6  ...  \\\n",
       "0  2014/1/1  豐原  AMB_TEMP    14    14    14    13    12    12    12  ...   \n",
       "1  2014/1/1  豐原       CH4   1.8   1.8   1.8   1.8   1.8   1.8   1.8  ...   \n",
       "2  2014/1/1  豐原        CO  0.51  0.41  0.39  0.37  0.35   0.3  0.37  ...   \n",
       "3  2014/1/1  豐原      NMHC   0.2  0.15  0.13  0.12  0.11  0.06   0.1  ...   \n",
       "4  2014/1/1  豐原        NO   0.9   0.6   0.5   1.7   1.8   1.5   1.9  ...   \n",
       "\n",
       "     14    15    16    17    18    19    20    21    22    23  \n",
       "0    22    22    21    19    17    16    15    15    15    15  \n",
       "1   1.8   1.8   1.8   1.8   1.8   1.8   1.8   1.8   1.8   1.8  \n",
       "2  0.37  0.37  0.47  0.69  0.56  0.45  0.38  0.35  0.36  0.32  \n",
       "3   0.1  0.13  0.14  0.23  0.18  0.12   0.1  0.09   0.1  0.08  \n",
       "4   2.5   2.2   2.5   2.3   2.1   1.9   1.5   1.6   1.8   1.5  \n",
       "\n",
       "[5 rows x 27 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>日期</th>\n      <th>測站</th>\n      <th>測項</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014/1/1</td>\n      <td>豐原</td>\n      <td>AMB_TEMP</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n      <td>13</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n      <td>...</td>\n      <td>22</td>\n      <td>22</td>\n      <td>21</td>\n      <td>19</td>\n      <td>17</td>\n      <td>16</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014/1/1</td>\n      <td>豐原</td>\n      <td>CH4</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>...</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n      <td>1.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014/1/1</td>\n      <td>豐原</td>\n      <td>CO</td>\n      <td>0.51</td>\n      <td>0.41</td>\n      <td>0.39</td>\n      <td>0.37</td>\n      <td>0.35</td>\n      <td>0.3</td>\n      <td>0.37</td>\n      <td>...</td>\n      <td>0.37</td>\n      <td>0.37</td>\n      <td>0.47</td>\n      <td>0.69</td>\n      <td>0.56</td>\n      <td>0.45</td>\n      <td>0.38</td>\n      <td>0.35</td>\n      <td>0.36</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014/1/1</td>\n      <td>豐原</td>\n      <td>NMHC</td>\n      <td>0.2</td>\n      <td>0.15</td>\n      <td>0.13</td>\n      <td>0.12</td>\n      <td>0.11</td>\n      <td>0.06</td>\n      <td>0.1</td>\n      <td>...</td>\n      <td>0.1</td>\n      <td>0.13</td>\n      <td>0.14</td>\n      <td>0.23</td>\n      <td>0.18</td>\n      <td>0.12</td>\n      <td>0.1</td>\n      <td>0.09</td>\n      <td>0.1</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014/1/1</td>\n      <td>豐原</td>\n      <td>NO</td>\n      <td>0.9</td>\n      <td>0.6</td>\n      <td>0.5</td>\n      <td>1.7</td>\n      <td>1.8</td>\n      <td>1.5</td>\n      <td>1.9</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>2.2</td>\n      <td>2.5</td>\n      <td>2.3</td>\n      <td>2.1</td>\n      <td>1.9</td>\n      <td>1.5</td>\n      <td>1.6</td>\n      <td>1.8</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抛去数据的前三列不要了\n",
    "data = data.iloc[:, 3:]\n",
    "# 将为NR的数据变为 0\n",
    "data[data == 'NR'] = 0\n",
    "raw_data = data.to_numpy()"
   ]
  },
  {
   "source": [
    "## Extract Features 特征提取 - 1 \n",
    "将原始的4320*18的资料依照每个月组成12个月 18*480的数据类型(12*18*480) 其中18是feature 480 是 20*24 得来的"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = {}\n",
    "for month in range(12):\n",
    "    sample = np.empty([18, 480]) # 创建一个空样本大小为18*480\n",
    "    for day in range(20): # 一个月只取了20天\n",
    "        # 从raw_data中取数据 将数据填充进 sample\n",
    "        sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
    "    month_data[month] = sample"
   ]
  },
  {
   "source": [
    "## Extract Features 特征提取 - 2\n",
    "每个月有480小时，每9个小时为一个data，每个月会有471个data，故总资料数为471\\*12笔，而每笔数据有9\\*18的feature(一个小时18个feature)\n",
    "\n",
    "对应的target则有471 * 12 个 （第10个小时的PM2.5）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入输出的大小\n",
    "x = np.empty([12 * 471, 18 * 9], dtype=float)\n",
    "y = np.empty([12 * 471, 1], dtype = float)\n",
    "\n",
    "for month in range(12):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):\n",
    "            # 防止今天的数据跑到明天去\n",
    "            if day == 19 and hour > 14:\n",
    "                continue\n",
    "            # 输入的sample大小为9*18\n",
    "            x[month * 471 + day * 24 + hour, :] = month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1,-1)\n",
    "            y[month * 471 + day + hour, 0] = month_data[month][9, day * 24 + hour + 9]\n"
   ]
  },
  {
   "source": [
    "## Normalize 归一化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = np.mean(x, axis=0)\n",
    "std_x = np.std(x, axis= 0)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]"
   ]
  },
  {
   "source": [
    "上面的数据处理部分已懵逼！ 需要再看看咋做的 并想为啥这样操作\n",
    "\n",
    "## Split Training Data Into \"train_set\" and \"validation_set\"\n",
    "生成训练用的数据集train_set和验证数据局validation_set\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# floor() 返回数字的下舍整数。 取百分之80做训练集 剩下的 百分之20做测试集\n",
    "x_train_set = x[: math.floor(len(x) * 0.8), :]\n",
    "y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
    "x_validation = x[math.floor(len(x) * 0.8):, :]\n",
    "y_validation = y[math.floor(len(x) * 0.8):, :]"
   ]
  },
  {
   "source": [
    "## Training\n",
    "使用Adagrad算法作为优化器\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1071.53it/s]\n",
      "Loss:8.823287772292002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 因为常数项的存在所以dim要多加一个维度\n",
    "dim = 18 * 9 + 1\n",
    "w = np.zeros([dim, 1])\n",
    "x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
    "\n",
    "# 设置学习率\n",
    "learning_rate = 100\n",
    "# 迭代次数\n",
    "iter_time = 1000\n",
    "# adagrad \n",
    "adagrad = np.zeros([dim, 1])\n",
    "eps = 0.000000001\n",
    "last_loss = 0\n",
    "for t in tqdm(range(iter_time)):\n",
    "    # rmse\n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2))/471/12)         \n",
    "    last_loss = loss\n",
    "    # 计算梯度\n",
    "    gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y)\n",
    "    # adgrade\n",
    "    adagrad += gradient ** 2\n",
    "    # 更新参数\n",
    "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "\n",
    "print(\"\\n\" + \"Loss:\" + str(last_loss))\n",
    "# 保存权重\n",
    "np.save('weight.npy', w)"
   ]
  },
  {
   "source": [
    "## Testing\n",
    "导入test data 并且以训练集的方式预处理，使得测试数据形成240个维度为18\\*9+1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('./test.csv', header = None, encoding = 'big5')\n",
    "test_data = testdata.iloc[:, 2:]\n",
    "test_data[test_data == 'NR'] = 0\n",
    "test_data = test_data.to_numpy()\n",
    "test_x = np.empty([240, 18*9], dtype = float)\n",
    "for i in range(240):\n",
    "    test_x[i, :] = test_data[18 * i: 18* (i + 1), :].reshape(1, -1)\n",
    "\n",
    "# 归一化\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1).astype(float)"
   ]
  },
  {
   "source": [
    "## Prediction \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入权重\n",
    "w = np.load('weight.npy')\n",
    "# 解决输出\n",
    "ans_y = np.dot(test_x, w)"
   ]
  },
  {
   "source": [
    "## Save Prediction to CSV File"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['id', 'value']\n['id_0', 2.741404287042598]\n['id_1', -4.370884456673592]\n['id_2', 18.26244373270194]\n['id_3', 9.598128127340377]\n['id_4', 2.0892488386282793]\n['id_5', 1.4738494998130225]\n['id_6', 7.002309849867746]\n['id_7', 4.225084371439914]\n['id_8', 3.1922017854384555]\n['id_9', 7.0000374111473604]\n['id_10', 1.6519333721442475]\n['id_11', 1.3413967050490694]\n['id_12', 0.8044668636103403]\n['id_13', 5.335244584422716]\n['id_14', 2.9786019573392304]\n['id_15', -1.6292954037544511]\n['id_16', 3.0581183366715585]\n['id_17', 6.016887626181646]\n['id_18', 0.1824775984498146]\n['id_19', -0.747441981553358]\n['id_20', 2.598173959640545]\n['id_21', -1.183035165744311]\n['id_22', 3.9779106193374396]\n['id_23', 1.4861291556116853]\n['id_24', 0.2242522454175493]\n['id_25', 7.600797728995835]\n['id_26', 8.134195848237]\n['id_27', -70.80100692026932]\n['id_28', 3.0767976597371054]\n['id_29', 4.793725407740482]\n['id_30', 12.07104554541126]\n['id_31', 0.9229460126120124]\n['id_32', -0.47614033491622587]\n['id_33', -1.796705496488335]\n['id_34', -2.560803709674591]\n['id_35', 1.4871255981427196]\n['id_36', -1.1027686981250673]\n['id_37', 2.019907607903299]\n['id_38', 5.601245801500596]\n['id_39', -0.20577799340463798]\n['id_40', -6.14501345246129]\n['id_41', 2.1727919305473193]\n['id_42', 1.5422026484871827]\n['id_43', 13.671056580551674]\n['id_44', 3.3190426489865494]\n['id_45', 13.905632010022487]\n['id_46', 4.708430122971356]\n['id_47', -3.5407623739160705]\n['id_48', 11.089419944735607]\n['id_49', -3.761457377406749]\n['id_50', -0.925880902104554]\n['id_51', 5.040791019107569]\n['id_52', 2.9369766727395508]\n['id_53', -3.1704874461421255]\n['id_54', 5.671414375446364]\n['id_55', -8.26203095804542]\n['id_56', 2.880069723381781]\n['id_57', 2.1168848972982253]\n['id_58', -1.5017629902786567]\n['id_59', -2.174218914189616]\n['id_60', 8.229782279103958]\n['id_61', 5.883196565125324]\n['id_62', 5.0883423289629635]\n['id_63', 2.384395579541609]\n['id_64', 3.1949420784523603]\n['id_65', 5.530271411567794]\n['id_66', 3.7465408900816546]\n['id_67', -0.7525476095079942]\n['id_68', -3.1485329160427753]\n['id_69', -1.0636212253493778]\n['id_70', -4.4642979085414005]\n['id_71', 7.358324361477276]\n['id_72', -6.928317226667215]\n['id_73', -6.791201179662398]\n['id_74', -0.09491916889864704]\n['id_75', -1.4719678538825605]\n['id_76', 7.051415507659122]\n['id_77', 7.140834732367418]\n['id_78', 6.62883663468515]\n['id_79', -1.0174475802708542]\n['id_80', 2.165388525265305]\n['id_81', 4.205619504964194]\n['id_82', 4.9526436127391555]\n['id_83', -2.040181136942323]\n['id_84', 3.047692688750745]\n['id_85', 9.441609010849149]\n['id_86', 0.37158522647073866]\n['id_87', -8.779591457475066]\n['id_88', 6.345006900767257]\n['id_89', 4.020610267707344]\n['id_90', 0.9915640764185554]\n['id_91', 1.2946721922131985]\n['id_92', -0.7848389410748347]\n['id_93', 6.982791561352606]\n['id_94', 3.0214689330516826]\n['id_95', -1.3838401139572802]\n['id_96', -0.11592264188680357]\n['id_97', 1.298163535956773]\n['id_98', 1.4714795050205751]\n['id_99', 6.21055617905182]\n['id_100', 0.4095494345173325]\n['id_101', 5.864006247881255]\n['id_102', 0.33975928071341954]\n['id_103', 1.3982740685204882]\n['id_104', -4.050050517805818]\n['id_105', 3.339858895697885]\n['id_106', 3.1392326494994194]\n['id_107', 4.390949466538892]\n['id_108', 4.945272597133112]\n['id_109', 1.6063291301498595]\n['id_110', 6.097944813478471]\n['id_111', 4.034499217075373]\n['id_112', 3.153304520162993]\n['id_113', -9.241270096638564]\n['id_114', 8.257137151098135]\n['id_115', 1.4473115014542994]\n['id_116', -0.6381516378149339]\n['id_117', 4.257645462332984]\n['id_118', -1.1627802937771676]\n['id_119', 2.883260618128947]\n['id_120', -0.2396839113257343]\n['id_121', 8.175872193873776]\n['id_122', 3.9863884600645854]\n['id_123', 2.9061660259893287]\n['id_124', 9.007919333441093]\n['id_125', 2.3673592999743516]\n['id_126', 5.453504877067562]\n['id_127', 6.019428726013805]\n['id_128', 10.25425522585763]\n['id_129', -1.7706814232677957]\n['id_130', 9.755173199775994]\n['id_131', -3.4818910289520275]\n['id_132', 2.639765670134196]\n['id_133', 10.582548680117766]\n['id_134', 7.715806236647305]\n['id_135', 1.4700697361051889]\n['id_136', 5.167375928462594]\n['id_137', 4.576129775429587]\n['id_138', -1.9382802504261747]\n['id_139', -0.36141126867406115]\n['id_140', 1.6372940544842542]\n['id_141', -4.20706022036917]\n['id_142', 8.765569381027696]\n['id_143', 9.661912120335163]\n['id_144', 3.612360105639871]\n['id_145', 6.700914583017915]\n['id_146', 1.734431192005374]\n['id_147', 7.028012534776565]\n['id_148', 4.989626212804092]\n['id_149', -3.934448586366333]\n['id_150', 2.7546761054703914]\n['id_151', -1.4971179157772543]\n['id_152', 1.6106855557960387]\n['id_153', 12.738186022422726]\n['id_154', -11.130367367700597]\n['id_155', 0.15577022382784378]\n['id_156', 6.149467716630223]\n['id_157', 3.624658294063064]\n['id_158', 10.489053964772005]\n['id_159', 1.222228213593695]\n['id_160', 1.7695841980500484]\n['id_161', -4.17255070573149]\n['id_162', 3.7571756248179344]\n['id_163', 3.054833432401444]\n['id_164', 0.22722697579457574]\n['id_165', -6.2814790341791635]\n['id_166', 1.489377791361072]\n['id_167', 12.984052420691015]\n['id_168', -2.112535326283819]\n['id_169', -4.774221646251654]\n['id_170', -3.4175008586313673]\n['id_171', 6.687941317425004]\n['id_172', 7.819821827536861]\n['id_173', 7.4466174614937515]\n['id_174', 6.66609936761424]\n['id_175', -3.978734118970273]\n['id_176', 5.707226889508721]\n['id_177', 0.20258163745346813]\n['id_178', -0.18388152204259]\n['id_179', 4.641306037363263]\n['id_180', 7.2231532667985]\n['id_181', -0.9101551825210805]\n['id_182', 4.188822114047198]\n['id_183', -5.328924003375842]\n['id_184', 0.4930738927905658]\n['id_185', 2.723978129176217]\n['id_186', 3.7609210334977963]\n['id_187', -6.236400480276512]\n['id_188', 2.6452103674665866]\n['id_189', -19.755113133007967]\n['id_190', -4.381499258320961]\n['id_191', 3.2665144763873677]\n['id_192', 8.10790002468763]\n['id_193', -0.5628544252305439]\n['id_194', 1.3034170517642458]\n['id_195', 2.1656111234777384]\n['id_196', 3.4146848544136637]\n['id_197', 7.440663940345672]\n['id_198', -4.267437694402908]\n['id_199', -2.9616549136948747]\n['id_200', 7.901489234345846]\n['id_201', 0.03769849575744999]\n['id_202', 3.6389010812580223]\n['id_203', -5.68500188483887]\n['id_204', 1.0116321717940728]\n['id_205', 8.956329779127278]\n['id_206', 6.634079499607324]\n['id_207', 4.383195801821946]\n['id_208', 6.091503907665739]\n['id_209', 2.9877265104650235]\n['id_210', 12.131727012437812]\n['id_211', 2.8948438652228936]\n['id_212', 6.311993625006117]\n['id_213', 4.202862244229348]\n['id_214', -1.3842875507008037]\n['id_215', 3.9190952837246495]\n['id_216', 6.999729713446495]\n['id_217', -0.6481004862510593]\n['id_218', -0.6104612520862034]\n['id_219', -4.134062496038894]\n['id_220', 6.0065426792038465]\n['id_221', 8.657384248858419]\n['id_222', 13.774198143499245]\n['id_223', -4.238574390417762]\n['id_224', 9.321766590701085]\n['id_225', 3.5278946157275914]\n['id_226', -1.6175133919415252]\n['id_227', 5.989660427064478]\n['id_228', 1.6894258597513212]\n['id_229', -2.2197535629332954]\n['id_230', 0.40117206620997337]\n['id_231', 1.322285942427592]\n['id_232', -1.7032322442276322]\n['id_233', -0.12680806570775616]\n['id_234', 7.62344562375512]\n['id_235', 3.2209993180309944]\n['id_236', -4.807476570066573]\n['id_237', 4.8152345962671035]\n['id_238', 3.408997659328489]\n['id_239', 6.577087236654499]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('prediction.csv', mode='w', newline='') as prediction_file:\n",
    "    csv_writer = csv.writer(prediction_file)\n",
    "    header = ['id', 'value']\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(240):\n",
    "        row = ['id_' + str(i), ans_y[i][0]]\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "source": [
    "## 总结\n",
    "结果好像不是很好哎，因为预测的pm2.5的值竟然有负数！！ 这是不可能的啊\n",
    "如何优化呢， 选择不同的优化器，是不用同的model（LSTM）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.29583333333333334"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(ans_y)):\n",
    "    if (ans_y[i] < 0):\n",
    "        count += 1\n",
    "\n",
    "count/len(ans_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}